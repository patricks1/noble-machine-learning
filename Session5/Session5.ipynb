{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Machine Learning\n",
    "\n",
    "### *Session \\#5*\n",
    "\n",
    "\n",
    "### Helpful shortcuts\n",
    "---\n",
    "\n",
    "**SHIFT** + **ENTER** ----> Execute Cell\n",
    "\n",
    "**UP/DOWN ARROWS** --> Move cursor between cells (then ENTER to start typing)\n",
    "\n",
    "**TAB** ----> See autocomplete options\n",
    "\n",
    "**ESC** then **b** ----> Create Cell \n",
    "\n",
    "**ESC** then **dd** ----> Delete Cell\n",
    "\n",
    "**\\[python expression\\]?** ---> Explanation of that Python expression\n",
    "\n",
    "**ESC** then **m** then __ENTER__ ----> Switch to Markdown mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Probability and Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**You are planning a picnic, but it's cloudy outside! Should we still go?**\n",
    "\n",
    "**1. We have data on 300 days, and 135 of them are cloudy. What's the probability of a cloudy day,** `P(C)`**?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. It only rains on 30 out of 300 days. What's the probability of rain,** `P(R)`**?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Of the rainy days, 15 of them were cloudy. What's the probability of** `P(C|R)` **?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Use Bayes' Theorem to find the chance of rain, given that it's cloudy:** `P(R|C)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. New example: Are you being cheated in a coin flip? Assume that 9 out of 10 coins are fair.**\n",
    "\n",
    "**What's the probability you're dealing with a fair coin** `P(F)`**? Probability of an unfair coin** `P(U)`**?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Now you see the coin land heads 4 times in a row.** \n",
    "\n",
    "**What's the probability of this happening with a fair coin, i.e.** `P(HHHH|F)` **?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Unfair coins land heads 90% of the time.** \n",
    "\n",
    "**What's the probability of this happening with an unfair coin, i.e.** `P(HHHH|U)` **?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use Bayes Theorem to compute the probability that the coin is unfair, i.e.** `P(U|HHHH)` \n",
    "\n",
    "Hint: You'll need `P(HHHH)`, the overall chance of getting 4 heads. To get this we need to combine `P(HHHH|F)` and `P(HHHH|U)`, weighted for how likely each type of coin is.\n",
    "\n",
    "Summed up:  `P(HHHH|F)P(F)` + `P(HHHH|U)P(U)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", encoding = 'latin-1')\n",
    "X = df['text']\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorize the words:** \n",
    "```\n",
    "vec = CountVectorizer(stop_words='english', max_features=20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create pipeline:** \n",
    "```\n",
    "pipe = make_pipeline(vec, MultinomialNB())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Curve:** \n",
    "```python\n",
    "model_vc = ValidationCurve(pipe, 'multinomialnb__alpha', range(1, 12))\n",
    "model_vc.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Create a variable** `ham` **for the text from rows of** `df` **that are categorized as ham.** \n",
    "\n",
    "**Likewise, create a variable** `spam` **for the text from rows of** `df` **that are categorized as spam**\n",
    "\n",
    "\n",
    "Hint: Use boolean fitering first, then grab the `text` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. The code below will fetch the number of times each feature (ie word) occurs**\n",
    "\n",
    "**Use** `plt.barh()` **to show a histogram of the most common** `ham` **words**\n",
    "\n",
    "Hint: `.barh()` expects a list of labels, then a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_counts = np.asarray(vec.fit_transform(ham).sum(axis=0))[0]\n",
    "ham_features = vec.get_feature_names()\n",
    "\n",
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Now fit** `vec` **to the** `spam` **dataset. Adapt the code above to create** `spam_counts` **and** `spam_features`\n",
    "\n",
    "**Use** `plt.barh()` **to show a histogram of the most common** `spam` **words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Create a pipeline with a new** `CountVectorizer()` **and a** `MultinomialNB()` **model. You will need to:** \n",
    "\n",
    "* Create the pipeline\n",
    "* Fit the model to the training set\n",
    "* Score the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. The model's** `alpha` **parameter adjusts how much.**\n",
    "\n",
    "**Use a validation curve to choose a good value for** `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Multi-Class and Twitter Bot \n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweepy\n",
    "import tweepy\n",
    "from random import choices\n",
    "\n",
    "tweets = pd.read_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Create a pipeline with a new CountVectorizer() saved as** `vec` **and a MultinomialNB() saved as** `model` **and train it on** `tweets` \n",
    "\n",
    "**What is the accuracy of the model?**\n",
    "\n",
    "Hint: For easy access, create `vec` and `model` before placing them in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets['content']\n",
    "y = tweets['author']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot a** `ConfusionMatrix` **of your model. Which celebrity is hardest to classify?**         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. CountVectorizer allows for many parameters to improve the quality of data it produces for your model. Use the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to fine-tune your model with different combinations**\n",
    "\n",
    "Note: We will learn how to automate this process with Grid Search in the next class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The code below will select words at random, according to how frequently they're used by the chosen celebrity**\n",
    "\n",
    "**Change the** `celeb_index` **and** `num_words` **to get different randomly generated tweets**\n",
    "\n",
    "Hint: Use `model.classes_` to choose a specific celebrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_index = 0\n",
    "num_words = 4\n",
    "\n",
    "words = choices(vec.get_feature_names(),\n",
    "                weights=model.feature_count_[celeb_index],\n",
    "                k=num_words)\n",
    "\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Run the code below to set up Tweepy**\n",
    "\n",
    "**Pass a string to** `api.update_status()` **to send a tweet:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler('8hQMoNize5oshYZjaqai1DyVR', 'UhaEatmV6a0PdeuM1RWnsMNOJFHEmyNcFpsYb46czvnPJtzF1E')\n",
    "auth.set_access_token('3629445439-YGOjZU7i4a455eDEtlUMmnx4koOYi0nax9ixGB7', 'eEwqBLLWKIHZAU9WwOFgAfRhclTNpUYTRG6j4k3EaJCkO')\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Add your code down here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
