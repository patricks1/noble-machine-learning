{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Machine Learning\n",
    "\n",
    "### *Session \\#6*\n",
    "\n",
    "\n",
    "### Helpful shortcuts\n",
    "---\n",
    "\n",
    "**SHIFT** + **ENTER** ----> Execute Cell\n",
    "\n",
    "**UP/DOWN ARROWS** --> Move cursor between cells (then ENTER to start typing)\n",
    "\n",
    "**TAB** ----> See autocomplete options\n",
    "\n",
    "**ESC** then **b** ----> Create Cell \n",
    "\n",
    "**ESC** then **dd** ----> Delete Cell\n",
    "\n",
    "**\\[python expression\\]?** ---> Explanation of that Python expression\n",
    "\n",
    "**ESC** then **m** then __ENTER__ ----> Switch to Markdown mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, ROCAUC\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"breast_cancer.csv\", usecols=range(1, 32))\n",
    "\n",
    "X = df.drop('diagnosis', 1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---\n",
    "**Create a decision tree:** \n",
    "```python\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print tree:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plot_tree(model, \n",
    "          feature_names=X.columns, \n",
    "          class_names=model.classes_, \n",
    "          filled=True,\n",
    "          rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Gini importance of features:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(model.feature_importances_, X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. In the decision tree graphed above, how would the following two cases be classified?**\n",
    "\n",
    "* concave_points_mean = 0.050\n",
    "* area_se = 42\n",
    "* concavity_worst = 0.5\n",
    "\n",
    "\n",
    "* concave points_mean = 0.092\n",
    "* area_se = 32\n",
    "* concavity_worst = 0.6\n",
    "\n",
    "\n",
    "*Hint: If the top line within each box is true, go left. False, go right.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the Gini impurity of the first cut? The second?**\n",
    "\n",
    "Gini reminder: Imagine randomly choosing a datapoint, then assign class label with probability according to proportion of classes. What's the chance of misclassification?\n",
    "\n",
    "<br>\n",
    "<div style=\"display: flex;\">\n",
    "    <img src=\"../images/gini1.png\"> \n",
    "    <img src=\"../images/gini2.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the accuracy score of the decision tree above?**\n",
    "\n",
    "**Retrain and remove the** `max_depth` **parameter. Compare the score on the training set and test sets. What is happening to the model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Use a validation curve to find where** `max_depth` **begins to become ineffective.**\n",
    "\n",
    "Hint: `ValidationCurve()` takes model, then parameter name, then values you want to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Retrain the model with** `max_depth` **set to the ideal value you found.**\n",
    "\n",
    "**Which features were most important to the decision tree?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a random forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foresti = RandomForestClassifier(n_estimators=100)\n",
    "foresti.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(foresti.feature_importances_, X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access internal decision trees:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foresti.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': range(100, 160, 10),\n",
    "          'max_depth': range(6,12,2)}\n",
    "grid = GridSearchCV(foresti, params).fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Redo the validation curve exercise with your RandomForest classifier.** \n",
    "\n",
    "**Do deeper trees cause overfitting?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. The** `class_weight` **parameter takes a dictionary of classes, and changes how important each class is to the model**\n",
    "\n",
    "**Try setting it to** `{'B': 10}` **to make the malignant cases 10x as important. Use a** `ConfusionMatrix` **visualizer to see how this affects the type of errors the model makes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Further parameters to** `RandomForestClassifier` **are:**\n",
    "\n",
    "    * max_depth -- # of layers in decision trees\n",
    "    * max_features -- # of columns used at each split\n",
    "    \n",
    "**Use grid search to optimize for these hyperparameters**\n",
    "\n",
    "Note: The more combinations you try, the longer this will run! Start with trying only a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. A major benefit of decision-tree and random-forest models is that they perform automatic feature selection.**\n",
    "\n",
    "**Run the code below to add 10 columns of random data to your dataset. Re-train your model and score it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = pd.DataFrame(np.random.randint(0,\n",
    "                                           100,\n",
    "                                           size=(len(df), 10)), \n",
    "                         columns=[f\"random_{i}\" for i in range(10)])\n",
    "\n",
    "big_df = pd.concat([df, random_df], axis=1)\n",
    "X_big = big_df.drop('diagnosis', 1)\n",
    "y_big = big_df['diagnosis']\n",
    "tts_big = train_test_split(X_big, y_big, random_state=100)\n",
    "tts_big[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Final Practice for Home: Start to Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Let's bring it all together! Here you will apply all the individual skills you've learned to a raw dataset.** \n",
    "\n",
    "**You will need to:** \n",
    "\n",
    "* Explore the data\n",
    "* Select an appropriate model\n",
    "* Split the data into X, y and train/test\n",
    "* Handle null values, if present\n",
    "* Do feature engineering\n",
    "* Use appropriate evaluation methods\n",
    "* Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"target\" column is what we want to predict\n",
    "# 0 = Bad Car, 3 = Very Good Car\n",
    "\n",
    "cars = pd.read_csv(\"cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"price\" column is what we want to predict\n",
    "\n",
    "diamonds = pd.read_csv(\"diamonds.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
